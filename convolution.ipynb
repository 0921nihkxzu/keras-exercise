{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'>Simple convolution example</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([\n",
    "    [1,1,1,1,-1,-1,-1],\n",
    "    [1,1,1,1,-1,-1,-1],\n",
    "    [1,1,1,1,-1,-1,-1],\n",
    "    [1,1,1,1,-1,-1,-1],\n",
    "    [1,1,1,1,-1,-1,-1],\n",
    "    [1,1,1,1,-1,-1,-1],\n",
    "    [1,1,1,1,-1,-1,-1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([\n",
    "    [1, 0, -1], \n",
    "    [1, 0, -1], \n",
    "    [1, 0, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = img.shape[0]\n",
    "f = W.shape[0]\n",
    "p = 0\n",
    "s = 1\n",
    "a = int((n+2*p-f)/s)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((a,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(a):\n",
    "    for j in range(a):\n",
    "        y[i, j] = np.sum((img[i:i+f,j:j+f]*W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> Basic convolution layer forwardprop and backprop </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 12\n",
    "nh_0 = 64\n",
    "nw_0 = 64\n",
    "nc_0 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = np.random.rand(m, nh_0, nw_0, nc_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining layer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik.utils.activations import relu, drelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 5\n",
    "fw = 7\n",
    "nc = 10\n",
    "s = 1\n",
    "ph = 0\n",
    "pw = 0\n",
    "g = relu\n",
    "dg = drelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = int((nh_0+2*ph-fh)/s)+1\n",
    "nw = int((nw_0+2*pw-fw)/s)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining layer variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(fh, fw, nc_0, nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.rand(1, 1, 1, nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing forwardprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardprop_v1(A_0, params):\n",
    "    \n",
    "    W, b, g, fh, fw, s, nh, nw, nc = params\n",
    "    \n",
    "    Z = np.zeros((m,nh,nw,nc))\n",
    "    \n",
    "    for i in range(nh):\n",
    "        \n",
    "        for j in range(nw):\n",
    "            \n",
    "            axes = tuple(i for i in range(1,len(Z.shape)))\n",
    "            \n",
    "            # Note on np.newaxis: extension of A dimension such that it is copied along the additional axis for multiplication\n",
    "            Z[:, i, j, :] = np.sum((A_0[:,i*s:i*s+fh,j*s:j*s+fw,:,np.newaxis]*W), axis=axes)\n",
    "            \n",
    "    Z += b\n",
    "    \n",
    "    A = g(Z)\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = forwardprop_v1(A0, [W, b, g, fh, fw, s, nh, nw, nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('forwardprop_v1(A0, [W, b, g, fh, fw, s, nh, nw, nc])', globals=globals(), number=10)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing backprop v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_v1(dA0, params):\n",
    "    \n",
    "    A, A0, W, dg = params\n",
    "    \n",
    "    m, nh_0, nw_0, nc_0 = A0.shape\n",
    "    fh, fw, _, nc = W.shape\n",
    "    \n",
    "    dZ = dg(A)*dA0\n",
    "    \n",
    "    axes = tuple(i for i in range(0,len(dZ.shape)-1))\n",
    "    db = 1./m * np.sum(dZ, axis=axes, keepdims=True)\n",
    "    \n",
    "    dW = np.zeros(W.shape)\n",
    "    dA = np.zeros(A0.shape)\n",
    "    \n",
    "    for i in range(nh):\n",
    "\n",
    "        for j in range(nw):\n",
    "\n",
    "                A0_ = A0[:,i:i+fh,j:j+fw,:,np.newaxis]\n",
    "                dZ_ = dZ[:,i,j,:][:,np.newaxis,np.newaxis,np.newaxis,:] \n",
    "\n",
    "                dW += np.sum(A0_*dZ_, axis=0, keepdims=False)\n",
    "\n",
    "                W_ = W[np.newaxis]\n",
    "\n",
    "                dA[:,i:i+fh,j:j+fw,:] += np.sum(W_*dZ_, axis=4, keepdims=False)\n",
    "\n",
    "    dW *= 1./m\n",
    "    \n",
    "    return dA, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA0 = np.random.random(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA, dW, db = backprop_v1(dA0, [A, A0, W, dg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('backprop_v1(dA0, [A, A0, W, dg])', globals=globals(), number=10)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution as matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easier to understand implementation using matrix multiplication: http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(A, fh, fw, s):\n",
    "    \n",
    "    m, nh_0, nw_0, nc_0 = A.shape\n",
    "    \n",
    "    nh = int((nh_0-fh)/s)+1\n",
    "    nw = int((nw_0-fw)/s)+1\n",
    "    \n",
    "    out = np.zeros((m, fh*fw*nc_0, nh*nw))\n",
    "    \n",
    "    for i in range(nh):\n",
    "\n",
    "        for j in range(nw):\n",
    "\n",
    "               out[:, :, i*nw+j] = A[:,i*s:i*s+fh,j*s:j*s+fw,:].reshape(m, fh*fw*nc_0)\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardprop_col(A0, params):\n",
    "    \n",
    "    W, b, g, fh, fw, s, nh, nw, nc = params\n",
    "    \n",
    "    A0_col = im2col(A0, fh, fw, s)\n",
    "    \n",
    "    m, _, _, nc_0 = A0.shape\n",
    "    \n",
    "    W = W.reshape(fh*fw*nc_0,nc).T\n",
    "    \n",
    "    Z = np.zeros((m, nh, nw, nc))\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        Z[i] = np.dot(W,A0_col[i]).T.reshape(1, nh, nw, nc)\n",
    "        \n",
    "    Z += b\n",
    "    \n",
    "    A = g(Z)\n",
    "    \n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0_col = im2col(A0, fh, fw, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = forwardprop_col(A0, [W, b, g, fh, fw, s, nh, nw, nc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if it produces the same result as previous implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(A_1 == A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('forwardprop_col(A0, [W, b, g, fh, fw, s, nh, nw, nc])', globals=globals(), number=100)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point to note is that im2col seems to take the majority of the computation. Can this be done more efficiently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('im2col(A0, fh, fw, s)', globals=globals(), number=100)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> An attempt to improve im2col speed </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2D case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea from: https://stackoverflow.com/questions/30109068/implement-matlabs-im2col-sliding-in-python/30110497"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a 2D test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.arange(15)[:,None]*5+np.arange(5)\n",
    "f = 3\n",
    "s = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_2d(A, f, s):\n",
    "    \n",
    "    nh_0, nw_0 = A.shape\n",
    "    \n",
    "    nh = int((nh_0-f)/s)+1\n",
    "    nw = int((nw_0-f)/s)+1\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for i in range(nh):\n",
    "\n",
    "        for j in range(nw):\n",
    "\n",
    "               out.append(A[i*s:i*s+f,j*s:j*s+f].flatten())\n",
    "                \n",
    "    return np.array(out).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_2d_idxs_bc(nh_0, nw_0, f, s):\n",
    "      \n",
    "    nh = int((nh_0-f)/s)+1\n",
    "    nw = int((nw_0-f)/s)+1\n",
    "    \n",
    "    # generating indexes of filter window on flattened 2D image\n",
    "    # for location (0,0) in the output image\n",
    "    filter_idxs = np.arange(f)[:,np.newaxis]*nw_0 + np.arange(f)\n",
    "\n",
    "    # generating the index in the flattened 2D image where the filter starts\n",
    "    # for each location in the output image\n",
    "    offset_idxs = (np.arange(nh)*s*nw_0)[:,np.newaxis] + np.arange(nw)*s\n",
    "    \n",
    "    # generating the full set of indices by generating a set of filter indices\n",
    "    # for each start location \n",
    "    idxs = (offset_idxs.flatten()[:,np.newaxis]+filter_idxs.flatten()).flatten()\n",
    "    \n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_2d_bc(A, f, s):\n",
    "    \n",
    "    nh_0, nw_0 = A.shape\n",
    "    \n",
    "    idxs = im2col_2d_idxs_bc(nh_0, nw_0, f, s)\n",
    "    \n",
    "    return A.flatten()[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the two implementations produce the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(im2col_2d_bc(V,f,s) == im2col_2d(V,f,s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('im2col_2d(V, f, s)', globals=globals(), number=10000)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('im2col_2d_idxs_bc(V.shape[0], V.shape[1], f, s)', globals=globals(), number=10000)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('im2col_2d_bc(V, f, s)', globals=globals(), number=10000)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy of using broadcasting is faster according to this simple test. It seems reasonable to extend to 3D. But its important to note that the generation of the indexes takes a significant portion of the time and this only needs to be done once per layer at initialization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extending to 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "nh_0 = 4\n",
    "nw_0 = 6\n",
    "nc_0 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = np.arange(m*nh_0*nw_0*nc_0).reshape(m, nh_0, nw_0, nc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each channel contains a 2D feature image\n",
    "A0[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 2\n",
    "fw = 3\n",
    "nc = 5\n",
    "s = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = int((nh_0-fh)/s)+1\n",
    "nw = int((nw_0-fw)/s)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_3d_idxs_bc(nh_0, nw_0, nc_0, fh, fw, s):\n",
    "    \n",
    "    nh = int((nh_0-fh)/s)+1\n",
    "    nw = int((nw_0-fw)/s)+1\n",
    "    \n",
    "    filter_idxs = ((np.arange(fh)[:,None]*nw_0*nc_0 + np.arange(fw)*nc_0)[:,:,None] + np.arange(nc_0)).flatten()\n",
    "    \n",
    "    offset_idxs = ((np.arange(nh)*s*nw_0*nc_0)[:,None] + np.arange(nw)*s*nc_0).flatten()\n",
    "    \n",
    "    idxs = offset_idxs[:,None] + filter_idxs\n",
    "    \n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_bc(A,fh,fw,s,idxs=None):\n",
    "    \n",
    "    m, nh_0, nw_0, nc_0 = A.shape\n",
    "    \n",
    "    nh = int((nh_0-fh)/s)+1\n",
    "    nw = int((nw_0-fw)/s)+1\n",
    "    \n",
    "    if type(idxs)==type(None):\n",
    "        idxs = im2col_3d_idxs_bc(nh_0, nw_0, nc_0, fh, fw, s)\n",
    "    \n",
    "    # Note: arranging colums where channels are appended to each other pixel by pixel\n",
    "    return np.swapaxes(A0.reshape(m,nh_0*nw_0*nc_0)[:,idxs].reshape(m,nh*nw,fh*fw*nc_0),1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arranging colums where each 2D image is flattened then appended channel by channel\n",
    "# np.swapaxes(A0.reshape(m,nh_0*nw_0,nc_0)[0,idxs,:].reshape(nw*nh,f*f,nc_0),1,2).reshape(nw*nh,f*f*nc_0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing that the two methods produce the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0_col = im2col(A0,fh,fw,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0_col_bc = im2col_bc(A0,fh,fw,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(A0_col == A0_col_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing speed of new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('im2col(A0,fh,fw,s)', globals=globals(), number=10000)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('im2col_bc(A0,fh,fw,s)', globals=globals(), number=10000)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed improvement is not significant when indexes have to be generated. However, what about in the case that they have already been calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = im2col_3d_idxs_bc(nh_0, nw_0, nc_0, fh, fw, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('im2col_bc(A0, fh, fw, s, idxs=idxs)', globals=globals(), number=100000)/100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experience a fair speedup with the new method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> Convolution backprop as matrix multiplication </font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik.utils.activations import relu, drelu\n",
    "from meik.utils.convolution import im2col_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "nh_0 = 4\n",
    "nw_0 = 6\n",
    "nc_0 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = np.arange(m*nh_0*nw_0*nc_0).reshape(m, nh_0, nw_0, nc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 2\n",
    "fw = 3\n",
    "nc = 5\n",
    "s = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = int((nh_0-fh)/s)+1\n",
    "nw = int((nw_0-fw)/s)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(fh, fw, nc_0, nc)\n",
    "b = np.random.rand(1, 1, 1, nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = relu\n",
    "dg = drelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = forwardprop(A0, [W, b, g, fh, fw, s, nh, nw, nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA0 = np.arange(m*nh*nw*nc).reshape(m, nh, nw, nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = im2col_idxs(nh_0, nw_0, nc_0, fh, fw, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_col(dA0, params):\n",
    "    \n",
    "    A, A0, A0_col, W, dg, idxs = params\n",
    "    \n",
    "    m, nh_0, nw_0, nc_0 = A0.shape\n",
    "    fh, fw, _, nc = W.shape\n",
    "    \n",
    "    nh = int((nh_0-fh)/s)+1\n",
    "    nw = int((nw_0-fw)/s)+1\n",
    "    \n",
    "    dZ = dA0*dg(A)\n",
    "            \n",
    "    W_ = W.reshape(fh*fw*nc_0, nc)\n",
    "    dZ_ = np.swapaxes(dZ.reshape(m, nh*nw, nc),1,2)\n",
    "    \n",
    "    dW_ = np.zeros(W_.shape)\n",
    "    dA_col = np.zeros(A0_col.shape)\n",
    "    \n",
    "    axes = tuple(np.arange(len(dZ.shape)-1))\n",
    "    db = 1./m * np.sum(dZ, axis=axes, keepdims=True)\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        dA_col[i] = np.dot(W_, dZ_[i])\n",
    "        dW_ += np.dot(A0_col[i], dZ_[i].T)\n",
    "    \n",
    "    dW_ *= 1./m\n",
    "\n",
    "    dA = np.zeros(A0.shape).flatten()\n",
    "    \n",
    "    # col2im_v1: doesn't seem efficient since we have to loop -> issue of no accumulation with fancy indexing\n",
    "    #    for i in range(nw*nh):\n",
    "    #        dA[:, idxs[i,:]] += dA_col[:,:,i]\n",
    " \n",
    "    # col2im_v2: using np.ufunc.at\n",
    "    # generating indices for flattening across training examples\n",
    "    idxs_m = ((np.arange((m),dtype=np.int8)*nh_0*nw_0*nc_0)[:,None] + idxs.flatten()).flatten()\n",
    "    \n",
    "    # flattening where features (f x f x nc_0), then training examples, are concatenated\n",
    "    dA_col = np.swapaxes(dA_col,1,2).flatten()\n",
    "    \n",
    "    # adds dA_col to the correct location in the input volume \n",
    "    # by accumulating the result for elements that are indexed multiple times\n",
    "    np.add.at(dA, idxs_m, dA_col)\n",
    "    \n",
    "    dA = dA.reshape(A0.shape)\n",
    "    \n",
    "    return dA, dW_.reshape(fh,fw,nc_0, nc), db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA, dW, db = backprop_col(dA0, [A, A0, A0_col, W, dg, idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA1, dW1, db1 = backprop_v1(dA0, [A, A0, W, dg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the two backprop methods produce the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all((dA - dA1) < 1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing the two versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('backprop_col(dA0, [A, A0, A0_col, W, dg, idxs])', globals=globals(), number=10000)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit('backprop_v1(dA0, [A, A0, W, dg])', globals=globals(), number=10000)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> Padding </font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, nh_0, nw_0, nc_0 = (2, 5, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, fw, s = (3,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ((np.arange(m)[:,None]*nh_0*nw_0*nc_0 + np.arange(nh_0))[:,:,None]*nw_0*nc_0 + np.arange(nw_0))[:,:,:,None]*nc_0 + np.arange(nc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Same'\n",
    "ph = (nh_0*(s-1)+fh-s)/2\n",
    "pw = (nw_0*(s-1)+fw-s)/2\n",
    "\n",
    "# For 'same' padding ensure the filter size and stride are appropriate: e.g. (nw*(s-1)+fw-s)/2 == 0\n",
    "assert (ph%1 == 0.0 and pw%1 == 0.0), \"Ensure (nw*(s-1)+fw-s)/2 == 0\"\n",
    "ph = int(ph)\n",
    "pw = int(pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(A, ph, pw):\n",
    "\n",
    "    m, nh_0, nw_0, nc_0 = A.shape\n",
    "\n",
    "    A_pad = np.zeros((m, nh_0 + 2*ph, nw_0 + 2*pw, nc_0))\n",
    "\n",
    "    A_pad[:, ph:-ph, pw:-pw, :] = A\n",
    "\n",
    "    return A_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depadding(A, ph, pw):\n",
    "    \n",
    "    m, nh_0, nw_0, nc_0 = A.shape\n",
    "    \n",
    "    A_depad = np.zeros((m, nh_0 - 2*ph, nw_0 - 2*pw, nc_0))\n",
    "    \n",
    "    A_depad = A[:, ph:-ph, pw:-pw, :]\n",
    "    \n",
    "    return A_depad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pad = padding(a, ph, pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_depad = depadding(a_pad, ph, pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(a_depad == a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> Convolution layer class </font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from meik.layers import Convolution3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 12\n",
    "nh_0 = 64\n",
    "nw_0 = 64\n",
    "nc_0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = np.random.rand(m, nh_0, nw_0, nc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (4, 7)\n",
    "nc = 10\n",
    "s = 3\n",
    "padding = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters, kernel_size = (3,3), stride = 1, padding = 'valid', inputs = None, units = None, activation = None, initialization = None, init_params = None\n",
    "L1 = Convolution3D(nc, kernel, stride = s, padding = padding, activation = 'relu', inputs = (nh_0, nw_0, nc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1.init(0, (nh_0, nw_0, nc_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing forwardprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = L1.forwardprop(A0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA, idxs_m = L1.backprop(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> Pooling </font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from meik.utils.convolution import im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "nh_0 = 4\n",
    "nw_0 = 4\n",
    "nc_0 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = np.arange(m*nh_0*nw_0*nc_0).reshape(m, nh_0, nw_0, nc_0)\n",
    "#A0 = np.random.rand(m, nh_0, nw_0, nc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 2\n",
    "fw = 2\n",
    "s = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(A0, fh, fw, s, mode='max'):\n",
    "    \n",
    "    m, _, _, nc_0 = A0.shape\n",
    "    \n",
    "    nh = (nh_0-fh)/s+1\n",
    "    nw = (nw_0-fw)/s+1\n",
    "    \n",
    "    assert(nh%1 == 0.0 and nw%1 == 0.0), \"Ensure the combination of input size, filter size and stride produce an integer output shape: e.g. ((nw_0+2*pw-fw)/s+1)%1 == 0\"\n",
    "\n",
    "    nh = int(nh)\n",
    "    nw = int(nw)\n",
    "    \n",
    "    A0_col = im2col(A0, fh, fw, s).reshape(m, fh*fw, nc_0, nh*nw)\n",
    "    \n",
    "    if mode=='max':\n",
    "        \n",
    "        A_pool = np.max(A0_col, axis=1)\n",
    "        idx = np.argmax(A0_col, axis=1)\n",
    "        \n",
    "    elif mode=='avg':\n",
    "        \n",
    "        A_pool = np.mean(A0_col, axis=1)\n",
    "        idx = None\n",
    "    \n",
    "    return np.swapaxes(A_pool,1,2).reshape(m, nh, nw, nc_0), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool_max, max_idxs = pool(A0, fh, fw, s, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool_avg, _ = pool(A0, fh, fw, s, mode='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un-pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik.utils.convolution import im2col_idxs\n",
    "\n",
    "def unpool(A_pool, fh, fw, s, max_idxs = None, mode='max'):\n",
    "    \n",
    "    m, nh, nw, nc_0 = A_pool.shape\n",
    "    \n",
    "    nh_0 = (nh - 1)*s + fh\n",
    "    nw_0 = (nw - 1)*s + fw\n",
    "    \n",
    "    # obtaining indices of im2col elements in flattened input\n",
    "    idxs = im2col_idxs(nh_0, nw_0, nc_0, fh, fw, s)\n",
    "    idxs_m = ((np.arange(m)*nh_0*nw_0*nc_0)[:,None] + idxs.flatten()).flatten()\n",
    "    \n",
    "    # empty target\n",
    "    A = np.zeros((m*nh_0*nw_0*nc_0)).flatten()\n",
    "    \n",
    "    if mode == 'max':\n",
    "\n",
    "        # converting indices from argmax format to indices of idxs_m\n",
    "        max_idxs = np.swapaxes(max_idxs, 1, 2) # rearranging for channels as last dimension\n",
    "        max_idxs = max_idxs*nc_0 + np.arange(nc_0)[None,None,:] # incrementing by channel\n",
    "        max_idxs += np.arange(nh*nw)[None,:,None]*fh*fw*nc_0 # incrementing by filter offset\n",
    "        max_idxs += np.arange(m)[:,None,None]*nh*nw*fh*fw*nc_0 # incrementing by training example\n",
    "        max_idxs = max_idxs.flatten()\n",
    "\n",
    "        # obtaining indices of pooling max elements in flattened input\n",
    "        idxs = idxs_m[max_idxs]\n",
    "        \n",
    "        # obtaining values\n",
    "        vals = A_pool.flatten()\n",
    "        \n",
    "    elif mode == 'avg':\n",
    "        \n",
    "        # obtaining indices of pooling max elements in flattened input\n",
    "        idxs = idxs_m\n",
    "        \n",
    "        # obtaining values\n",
    "        vals = 1./(fh*fw) * (np.swapaxes(A_pool[:,:,:,:,None] + np.arange(fh*fw)*0,3,4)).flatten()\n",
    "        \n",
    "    # 0btaining de-pooled A\n",
    "    np.add.at(A, idxs, vals)\n",
    "        \n",
    "    return A.reshape(m, nh_0, nw_0, nc_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpooled_max = unpool(A_pool_max, fh, fw, s, max_idxs = max_idxs, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpooled_avg = unpool(A_pool_avg, fh, fw, s, mode='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0[0,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool_max[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpooled_max[0,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool_avg[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpooled_avg[0,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik.layers import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1.init(0, (nh_0,nw_0,nc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool = P1.forwardprop(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpool = P1.backprop(A_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpool[0,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2 = Pool(mode='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2.init(0, (nh_0,nw_0,nc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool_avg = P2.forwardprop(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpool_avg = P2.backprop(A_pool_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pool_avg[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_unpool_avg[0,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> Flatten layer </font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from meik.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "nh_0 = 4\n",
    "nw_0 = 4\n",
    "nc_0 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = np.arange(m*nh_0*nw_0*nc_0).reshape(m, nh_0, nw_0, nc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1.init(0, (nh_0,nw_0,nc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = F1.forwardprop(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0_f = F1.backprop(F1.forwardprop(A0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(A0_f == A0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='068090'> MNIST </font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "    \n",
    "    shape = tuple(list(y.shape)+[np.max(y)+1])\n",
    "    l = np.zeros(shape)\n",
    "    \n",
    "    l[np.arange(l.shape[0]),y] = 1\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = one_hot_encode(y_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = one_hot_encode(y_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST With fully connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, h, w = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(m, h*w).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, h, w = x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test.reshape(n, h*w).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik.models import Sequential\n",
    "from meik.layers import Layer, Dense, Dropout, Batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=64, activation='relu', inputs=28*28))\n",
    "model.add(Batch_norm())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Batch_norm())\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Batch_norm())\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik import optimizers\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'binary_crossentropy', 'confusion_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(loss='categorical_crossentropy', optimizer=optimizer, eval_metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_train, Y_train, batch_size=64, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik.utils.misc import plot_training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(model, loss=model.params['loss'], mode='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST with Convolution3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train\n",
    "Y_train = one_hot_encode(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test\n",
    "Y_test = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, h, w = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik.models import Sequential\n",
    "from meik.layers import Convolution3D, Pool, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution3D(32, (3,3), stride = 1, padding = 'valid', activation = 'relu', inputs = (h,w,1)))\n",
    "model.add(Convolution3D(64, (3,3), stride = 1, padding = 'valid', activation = 'relu'))\n",
    "model.add(Pool(kernel_size=(2,2), stride=2, mode='max'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meik import optimizers\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'binary_crossentropy', 'confusion_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(loss='categorical_crossentropy', optimizer=optimizer, eval_metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Batch size must be less than or equal to training examples m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b1f702c9ce4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/meik/meik/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y, batch_size, epochs, verbose)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mX_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Batch size must be less than or equal to training examples m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Batch size must be less than or equal to training examples m"
     ]
    }
   ],
   "source": [
    "model.train(X_train, Y_train, batch_size=64, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
